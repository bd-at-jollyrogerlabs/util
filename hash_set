/** -*- mode: c++ -*-
 *
 * hash_set
 *
 * Highly configurable hash set implementation with an interface that
 *  is compatible with std::unordered_set.
 *
 * Copyright (C) 2015 Brian Davis
 * All Rights Reserved
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are
 * met:
 *
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 *
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
 * HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *
 * Limited copying permission is given solely
 * for self-educational purpose.
 *
 * Author: Brian Davis <bd@jollyrogerlabs.com>
 *
 */

#if !defined(JRL_UTIL_HASH_SET_GUARD)
#define JRL_UTIL_HASH_SET_GUARD 1

#include <cassert>

#include <experimental/optional>
#include <functional>
#include <list>
#include <vector>

#include <boost/iterator.hpp>
#include <boost/iterator/iterator_facade.hpp>

#include "jrl_macro"
#include "jrl_metaprogram"

namespace jrl
{

// ********** policy tags **********

struct key_extractor_tag {};

struct predicate_tag {};

struct allocator_tag {};

struct hash_function_tag {};

struct table_length_tag {};

struct rehash_tag {};

struct bucket_container_tag {};

// ********** policy implementation classes **********

// ***** key extractor policies *****

/**
 * default policy: key type is the same as value type
 * (e.g. hash_set<std::string>)
 */
struct default_key_extractor_policy
{
  template<typename ValueType>
  struct rebind
  {
    using key_type = ValueType;

    static const key_type &
    get_key(const ValueType &arg) noexcept
    {
      return arg;
    }

    static const bool can_get_key_from_constructor = true;

    static const key_type &
    key_from_ctor_args(key_type &&arg) noexcept
    {
      return arg;
    }
  };
};

/**
 * policy: extract the key from the first element of a std::pair
 *
 * NOTE: this is the correct policy for hash_map
 */
struct pair_first_element_key_extractor_policy
  : public key_extractor_tag
{
  template<typename ValueType>
  struct rebind
  {
    using key_type = ValueType;

    template<typename MappedType>
    static const key_type &
    get_key(const std::pair<key_type, MappedType> &arg) noexcept
    {
      return arg.first;
    }

    static const bool can_get_key_from_constructor = true;

    template<typename MappedType>
    static const key_type &
    key_from_ctor_args(const key_type&& key, const MappedType&& val) noexcept
    {
      return key;
    }
  };
};

// ***** predicate policies *****

/**
 * default policy: use std::equal_to
 */
struct default_predicate_policy
{
  template<typename KeyType>
  struct rebind : public std::equal_to<KeyType>
  {
  };
};

// ***** allocator policies *****

/**
 * default policy: allocate containers using std::allocator
 */
struct default_allocator_policy
{
  template<typename ValueType, template<typename...> class ContainerType>
  struct rebind
  {
    using type = ContainerType<ValueType, std::allocator<ValueType>>;
  };
};

// @todo think about how to handle stateful allocators

// @todo add pool/arena allocator policy

// @todo add custom allocator policy

// ***** hash function policies *****

/**
 * policy: calculate the hash value using std::hash
 */
struct default_hash_policy
{
  template<typename KeyType, typename SizeType>
  struct rebind
  {
    SizeType
    operator()(const KeyType &key) const noexcept
    {
      return std::hash<KeyType>()(key);
    }
  };
};

/**
 * policy: no hash calculation, the key value is passed through
 * unchanged.
 */
struct trivial_hash_policy : public hash_function_tag
{
  template<typename KeyType, typename SizeType>
  struct rebind
  {
    SizeType
    operator()(const KeyType &key) const noexcept
    {
      return static_cast<size_t>(key);
    }
  };
};

/**
 * policy: allow a free function (subprogram) for calculating hash
 * values.
 */
template<typename Derived>
struct free_function_hash_policy : public hash_function_tag
{
  template<typename KeyType, typename SizeType>
  struct rebind
  {
    SizeType
    operator()(const KeyType &key) const noexcept
    {
      return Derived::hash(key);
    }
  };
};

// ***** table length style policies *****

/**
 * default policy: table length is a prime number and hash values are
 * mapped to buckets using modulus (AKA operator%)
 */
struct default_table_length_policy
{
  template<typename SizeType>
  struct rebind
  {
    rebind()
    {
    }

    static SizeType
    initial_bucket_count() noexcept
    {
      return primes(INITIAL_BUCKET_COUNT_IDX);
    }

    /**
     * return the next legal bucket count that is greater than the
     * argument bucket count.
     */
    static SizeType
    next_bucket_count(const SizeType bucket_count)
    {
      size_t idx = 0;
      SizeType result = primes(idx);
      while (result <= bucket_count) {
	++idx;
	result = primes(idx);
      }
      return result;
    }

    static SizeType
    hash_to_bucket(const SizeType hash,
		   const SizeType bucket_count) noexcept
    {
      // @todo sanity check: ensure that bucket_count is in the set of
      // primes
      return hash % bucket_count;
    }

  private:

    static SizeType
    primes(const size_t idx)
    {
      static const std::vector<SizeType> PRIMES{
	17, 29, 37, 53, 67, 79, 97, 131, 193, 257, 389, 521, 769,
	1031, 1543, 2053, 3079, 6151, 12289, 24593, 49157, 98317,
	196613, 393241, 786433, 1572869, 3145739, 6291469,
	12582917, 25165843, 50331653, 100663319, 201326611,
	402653189, 805306457, 1610612741, 3221225473, 4294967291
      };
      return PRIMES.at(idx);
    }

  static const SizeType INITIAL_BUCKET_COUNT_IDX = 7;
  };
};

/**
 * policy: table length is a power of two and hash values are mapped
 * to buckets by masking away higher order bits
 */
struct power_of_two_length_table_policy : table_length_tag
{
  template<typename SizeType>
  struct rebind
  {
    rebind()
    {
    }

    static SizeType
    initial_bucket_count()
    {
      return INITIAL_BUCKET_COUNT;
    }

    /**
     * return the next legal bucket count that is greater than the
     * argument bucket count.
     */
    static SizeType
    next_bucket_count(const SizeType bucket_count)
    {
      SizeType result = 1;
      while (result <= bucket_count) {
	result <<= 1;
      }
      return result;
    }

    static SizeType
    hash_to_bucket(const SizeType hash,
		   const SizeType bucket_count) noexcept
    {
      // @todo sanity check: ensure that bucket_count is a power of 2
      return hash & (bucket_count - 1);
    }

  private:
    static const SizeType INITIAL_BUCKET_COUNT = 128;
  };
};

// ***** rehash policies *****

template<typename SizeType>
using RehashCheckResult = std::experimental::optional<SizeType>;

/**
 * default policy: calculate the load factor and compare it to a
 * threshold in order to determine if the table should be rehashed
 */
template<typename SizeType, typename TableStyle, typename Derived>
struct load_factor_rehash
{
  using CheckResult = RehashCheckResult<SizeType>;

  /**
   * return nullopt_t if the table does not need to be rehashed, or
   * return the new bucket count if it does
   */
  static CheckResult
  rehash_check(SizeType current_bucket_count,
	       SizeType next_entry_count)
  {
    float load_factor = static_cast<float>(next_entry_count) /
      static_cast<float>(current_bucket_count);
    SizeType next_bucket_count;
    if (load_factor <= Derived::get_threshold()) {
      return std::experimental::nullopt;
    }
    while (load_factor > Derived::get_threshold()) {
      next_bucket_count =
	TableStyle::next_bucket_count(current_bucket_count);
      load_factor = static_cast<float>(next_entry_count) /
	static_cast<float>(next_bucket_count);
    }
    return next_bucket_count;
  }
};

/**
 * default policy for load_factor_rehash: rehash when the load factor
 * exceeds 1.5
 */
struct default_rehash_policy
{
  constexpr static float get_threshold() noexcept { return 1.5; }

  template<typename SizeType, typename TableStyle>
  struct rebind
    : public load_factor_rehash<SizeType, TableStyle,
				default_rehash_policy>
  {
  };
};

/**
 * policy: load factor rehash with custom threshold
 *
 * NOTE: threshold value is specified by deriving from this class
 * using CRTP and providing a get_threshold() function in the derived
 * class.
 */
template<typename Derived>
struct custom_threshold_rehash_policy : rehash_tag
{
  constexpr static float
  get_threshold() noexcept
  {
    return Derived::get_threshold();
  }

  template<typename SizeType, typename TableStyle>
  struct rebind
    : public load_factor_rehash<SizeType, TableStyle, Derived>
  {
  };
};

/**
 * policy: never rehash the table
 */
struct no_rehash_policy : rehash_tag
{
  template<typename SizeType, typename TableStyle>
  struct rebind
  {
    using CheckResult = RehashCheckResult<SizeType>;

      static CheckResult
      rehash_check(SizeType current_bucket_count,
		   SizeType next_entry_count)
    {
      return std::experimental::nullopt;
    }
  };
};

// ***** bucket container policies *****

/**
 * default policy: bucket container is std::vector
 */
struct default_bucket_container_policy
{
  template <typename ValueType, typename AllocPolicy>
  struct rebind
  {
    // rebind via allocator policy
    using type =
      typename AllocPolicy::template rebind<ValueType, std::vector>::type;
  };
};

/**
 * policy: bucket container is std::list
 */
struct std_list_bucket_container_policy : bucket_container_tag
{
  template <typename ValueType, typename AllocPolicy>
  struct rebind
  {
    // rebind via allocator policy
    using type =
      typename AllocPolicy::template rebind<ValueType, std::list>::type;
  };
};

// @todo add custom container policy choice

namespace detail
{

// ********** policy binder definitions **********

// ***** key extractor policy  binder *****

DEFINE_POLICY_BINDER(key_extractor_policy_binder,
		     default_key_extractor_policy,
		     key_extractor_tag);

// ***** predicate policy  binder *****

DEFINE_POLICY_BINDER(predicate_policy_binder,
		     default_predicate_policy,
		     predicate_tag);

// ***** allocator policy binder *****

DEFINE_POLICY_BINDER(allocator_policy_binder,
		     default_allocator_policy,
		     allocator_tag);

// ***** hash function policy binder *****

DEFINE_POLICY_BINDER(hash_function_policy_binder,
		     default_hash_policy,
		     hash_function_tag);

// ***** table length style policy binder *****

DEFINE_POLICY_BINDER(table_length_policy_binder,
		     default_table_length_policy,
		     table_length_tag);

// ***** rehash policy binder *****

DEFINE_POLICY_BINDER(rehash_policy_binder,
		     default_rehash_policy,
		     rehash_tag);

// ***** container type policy binder *****

DEFINE_POLICY_BINDER(bucket_container_policy_binder,
		     default_bucket_container_policy,
		     bucket_container_tag);

} // namespace detail

/**
 * Policy-based hash_set container.
 *
 * @todo full documentation of available policies
 */
template<typename ValueType, typename... Policies>
class hash_set
{
  // policy configurations
  using KeyExtractorBinding = detail::key_extractor_policy_binder<Policies...>;
  using PredicateBinding = detail::predicate_policy_binder<Policies...>;
  using AllocatorBinding = detail::allocator_policy_binder<Policies...>;
  using HashFunctionBinding = detail::hash_function_policy_binder<Policies...>;
  using TableLengthBinding = detail::table_length_policy_binder<Policies...>;
  using RehashBinding = detail::rehash_policy_binder<Policies...>;
  using BucketContainerBinding =
    detail::bucket_container_policy_binder<Policies...>;

  using KeyExtractorPolicy = typename KeyExtractorBinding::type;
  using PredicatePolicy = typename PredicateBinding::type;
  using AllocatorPolicy = typename AllocatorBinding::type;
  using HashFunctionPolicy = typename HashFunctionBinding::type;
  using TableLengthPolicy = typename TableLengthBinding::type;
  using RehashPolicy = typename RehashBinding::type;
  using BucketContainerPolicy = typename BucketContainerBinding::type;

  using ParamCounter = jrl::param_pack_size<Policies...>;
  using PolicyBindCounter =
    jrl::policy_bind_counter<KeyExtractorBinding,
			     PredicateBinding,
			     AllocatorBinding,
			     HashFunctionBinding,
			     TableLengthBinding,
			     RehashBinding,
			     BucketContainerBinding
			     >;

  // policy configuration check: the length of the policy template
  // pack must equal the number of matched policies.
  static_assert((ParamCounter::value == PolicyBindCounter::value),
		"extraneous type specified in hash_table policies");

  // rebind parameterized policies
  using BucketType =
    typename BucketContainerPolicy::template rebind<ValueType,
						    AllocatorPolicy>::type;
  using TableType =
    typename AllocatorPolicy::template rebind<BucketType, std::vector>::type;
  using Extractor =
    typename KeyExtractorPolicy::template rebind<ValueType>;
  using Predicate =
    typename PredicatePolicy::template rebind<typename Extractor::key_type>;
  using TableLength =
    typename TableLengthPolicy::template rebind<typename TableType::size_type>;
  using Hasher =
    typename HashFunctionPolicy::template rebind<typename Extractor::key_type,
						 typename TableType::size_type>;
  using Rehasher =
    typename RehashPolicy::template rebind<typename TableType::size_type,
					   TableLength>;

public:
  using key_type = typename Extractor::key_type;
  using value_type = ValueType;
  using size_type = typename TableType::size_type;

  // @todo iterator will be different (modified TableIterator) for
  // open addressing
  template<bool IsConst>
  class IteratorImpl
    : public boost::iterator_facade<IteratorImpl<IsConst>,
				    ValueType,
				    std::forward_iterator_tag>
  {
    // type used for the table pointer that is stored in the iterator
    using ItrTableType = SELECTIVE_CONST(IsConst, TableType);
    using TableIterator =
      typename std::conditional<IsConst,
				typename TableType::const_iterator,
				typename TableType::iterator>::type;
    using BucketIterator =
      typename std::conditional<IsConst,
				typename BucketType::const_iterator,
				typename BucketType::iterator>::type;
  public:
    DEFAULT_CONSTRUCTABLE(IteratorImpl);
    DEFAULT_COPYABLE(IteratorImpl);
    DEFAULT_MOVEABLE(IteratorImpl);

    explicit IteratorImpl(ItrTableType *table)
      : table_(table), tblItr_(table->begin()),
      	bktItr_(std::begin(*tblItr_))
    {
      if (tblItr_->empty()) {
	// call increment to find the first valid bucket
	increment();
      }
    }

    IteratorImpl(ItrTableType *table, size_type tblIdx, BucketIterator &&bktItr)
      : table_(table), tblItr_(table_->begin() + tblIdx), bktItr_(std::move(bktItr))
    {
    }

  private:
    friend class boost::iterator_core_access;
    using Type = IteratorImpl<IsConst>;

#   define SANITY_CHECK()					\
    do {							\
      assert((nullptr == table_) ||				\
	     (table_->end() != tblItr_) ||			\
	     (std::end(*tblItr_) != bktItr_));			\
    } while(0)

    void
    increment()
    {
      SANITY_CHECK();
      // if the bucket index can be incremented by 1 and remain lower
      // than the bucket size then the next entry is in the current
      // bucket, increment the index and return
      if (std::end(*tblItr_) != bktItr_) {
	BucketIterator cpy(bktItr_);
	++cpy;
	if (std::end(*tblItr_) != cpy) {
	  ++bktItr_;
	  return;
	}
      }
      // skip over empty buckets
      do {
	++tblItr_;
      } while ((table_->end() != tblItr_) && tblItr_->empty());
      // check for end of iteration
      if (tblItr_ != table_->end()) {
	// current bucket contains the next valid entry
	bktItr_ = std::begin(*tblItr_);
	return;
      }
      // no valid entries remaining
      *this = Type();
    }

    bool
    equal(const Type &that) const
    {
      SANITY_CHECK();
      return (table_ == that.table_) &&
	(tblItr_ == that.tblItr_) &&
	(bktItr_ == that.bktItr_);
    }

    ValueType &
    dereference() const
    {
      return *bktItr_;
    }

#   undef SANITY_CHECK

    ItrTableType *table_;
    TableIterator tblItr_;
    BucketIterator bktItr_;
  };

  using iterator = IteratorImpl<false>;
  using const_iterator = IteratorImpl<true>;

  hash_set()
    : table_(TableLength::initial_bucket_count(), BucketType()), entry_count_(0)
  {
  }

  DEFAULT_COPYABLE(hash_set);
  DEFAULT_MOVEABLE(hash_set);
  DEFAULT_DESTRUCTABLE(hash_set);

  bool
  empty() const noexcept
  {
    return 0 == entry_count_;
  }

  size_type
  size() const noexcept
  {
    return entry_count_;
  }

  size_type
  buckets() const
  {
    return table_.size();
  }

  iterator
  begin()
  {
    return iterator(&table_);
  }

  const_iterator
  begin() const
  {
    return const_iterator(&table_);
  }

  iterator
  end()
  {
    return iterator();
  }

  const_iterator
  end() const
  {
    return const_iterator();
  }

  const_iterator
  cbegin() const
  {
    return const_iterator(&table_);
  }

  const_iterator
  cend() const
  {
    return const_iterator();
  }

  inline iterator
  find(const ValueType &value)
  {
    return find_internal<false>(this, value);
  }

  inline const_iterator
  find(const ValueType &value) const
  {
    return find_internal<true>(this, value);
  }

  size_type
  count(const ValueType &value) const
  {
    // @todo not suitable for multi set/map
    auto entry = find(value);
    if (end() == entry) {
      return 0;
    }
    return 1;
  }

  // @todo use find_internal here?
  template<typename... Args>
  std::pair<iterator, bool>
  emplace(Args &&... args)
  {
    // @todo clean up this implementation (especially factoring out common code)
    if (Extractor::can_get_key_from_constructor) {
      const key_type &key =
	Extractor::key_from_ctor_args(std::forward<Args>(args)...);
      size_type idx = TableLength::hash_to_bucket(hasher_(key), buckets());
      {
	BucketType &bucket(table_.at(idx));
	const auto entry =
	  find_if(std::begin(bucket), std::end(bucket),
		  [key](const auto &entry) {
		    return (Predicate()(key, Extractor::get_key(entry)));
		  });
	if (std::end(bucket) != entry) {
	  // entry already exists
	  return std::make_pair(iterator(), false);
	}
      }

      // entry does not yet exist, insert it

      // rehash, if necessary
      const auto new_bucket_count =
	Rehasher::rehash_check(buckets(), size() + 1);
      if (new_bucket_count) {
	rehash_internal(*new_bucket_count);
	idx = TableLength::hash_to_bucket(hasher_(key), buckets());
      }
      BucketType &bucket(table_.at(idx));
      auto itr = bucket.emplace(std::end(bucket), std::forward<Args>(args)...);
      ++entry_count_;
      return std::make_pair(iterator(&table_, idx, std::move(itr)), true);
    }
    // @todo can be done better for cases other than array
    ValueType value = ValueType(args...);
    size_type idx = bucket(value);
    {
      const auto &key = Extractor::get_key(value);
      BucketType &bucket(table_.at(idx));
      const auto entry =
	find_if(std::begin(bucket), std::end(bucket),
		[key](const auto &entry) {
		  return (Predicate()(key, Extractor::get_key(entry)));
		});
      if (std::end(bucket) != entry) {
	// entry already exists
	return std::make_pair(iterator(), false);
      }
    }

    // entry does not yet exist, insert it

    // rehash, if necessary
    const auto new_bucket_count = Rehasher::rehash_check(buckets(), size() + 1);
    if (new_bucket_count) {
      rehash_internal(*new_bucket_count);
      idx = bucket(value);
    }
    BucketType &bucket(table_.at(idx));
    auto itr = bucket.emplace(std::end(bucket), std::move(value));
    ++entry_count_;
    return std::make_pair(iterator(&table_, idx, std::move(itr)), true);
  }

  // template<typename... Args>
  // iterator
  // emplace_hint(const_iterator pos, Args &&... args)
  // {
  //   // @todo
  // }

  /**
   * insert a (key, value) pair into the map, overwriting any previous
   * value associated with the same key
   */
  // @todo use find_internal here?
  std::pair<iterator, bool>
  insert(const ValueType &value)
  {
    size_type idx = bucket(value);
    {
      const auto &key = Extractor::get_key(value);
      BucketType &bucket(table_.at(idx));
      const auto entry =
	find_if(std::begin(bucket), std::end(bucket),
		[key](const auto &entry) {
		  return (Predicate()(key, Extractor::get_key(entry)));
		});
      if (std::end(bucket) != entry) {
	// entry already exists
	return std::make_pair(iterator(), false);
      }
    }

    // @todo use RAII to restore original state on exception

    // entry does not yet exist, insert it

    // rehash, if necessary
    const auto new_bucket_count =
      Rehasher::rehash_check(buckets(), size() + 1);
    if (new_bucket_count) {
      rehash_internal(*new_bucket_count);
      idx = bucket(value);
    }
    BucketType &bucket(table_.at(idx));
    auto itr = bucket.insert(std::end(bucket), value);
    ++entry_count_;
    return std::make_pair(iterator(&table_, idx, std::move(itr)), true);
  }

  // iterator
  // erase(const_iterator pos)
  // {
  //   // @todo
  // }

  // void
  // clear() // @todo noexcept??
  // {
  //   // @todo
  // }

  void
  swap(hash_set &tgt)
  {
    table_.swap(tgt.table_);
    std::swap(entry_count_, tgt.entry_count_);
    std::swap(hasher_, tgt.hasher_);
  }

  inline size_type
  bucket_count()
  {
    return table_.size();
  }

  inline size_type
  bucket_size(size_type idx) const
  {
    return table_[idx].size();
  }

  inline size_type
  bucket(const ValueType &value) const
  {
    return TableLength::hash_to_bucket(hasher_(Extractor::get_key(value)),
				       buckets());
  }

  inline float
  load_factor() const noexcept
  {
    return load_factor(entry_count_);
  }

  // float
  // max_load_factor() const noexcept
  // {
  //   // @todo ??
  // }

  void
  rehash(const size_type new_bucket_count)
  {
    auto rehash_check_result =
      Rehasher::rehash_check(new_bucket_count, size());
    if ((rehash_check_result) && (buckets() != *rehash_check_result)) {
      rehash_internal(*rehash_check_result);
    }
  }

private:
  using BucketIterator = typename BucketType::iterator;
  using BucketConstIterator = typename BucketType::const_iterator;
  using TableIterator = typename TableType::iterator;
  using TableConstIterator = typename TableType::const_iterator;
  using TableSearchResult =
    std::pair<std::experimental::optional<BucketIterator>, size_type>;
  using HashSetType = hash_set<ValueType, Policies...>;

  float
  load_factor(size_t entry_count) const noexcept
  {
    return static_cast<float>(entry_count) / static_cast<float>(table_.size());
  }

  template<bool IsConst>
  static typename std::conditional<IsConst, const_iterator, iterator>::type
  find_internal(SELECTIVE_CONST(IsConst, HashSetType) *obj,
		const ValueType &value)
  {
    using TItr =
      typename std::conditional<IsConst, const_iterator, iterator>::type;
    const auto &key = Extractor::get_key(value);
    size_type idx = obj->bucket(value);
    SELECTIVE_CONST(IsConst, TableType) *table(&obj->table_);
    decltype(auto) bucket(table->at(idx));
    decltype(auto) entry =
      find_if(std::begin(bucket), std::end(bucket),
	      [key](const auto &entry) {
		return (Predicate()(key, Extractor::get_key(entry)));
	      });
    if (std::end(bucket) == entry) {
      return TItr();
    }
    return TItr(table, idx, std::move(entry));
  }

  /**
   * increase the number of table entries to the next size and then
   * reinsert all current elements.
   */
  void
  rehash_internal(const size_type new_bucket_count)
  {
    // @todo use RAII to restore original state on exception
    TableType temp_copy(table_);
    table_ = TableType(new_bucket_count, BucketType());
    UNUSED const size_type old_entry_count = entry_count_;
    // NOTE: reset the entry count to 0 since it will be updated
    // automatically by calls to insert()
    entry_count_ = 0;
    for (auto bucket : temp_copy) {
      for (auto entry : bucket) {
	insert(entry);
      }
    }
    assert(old_entry_count == entry_count_);
  }

  TableType table_;
  size_type entry_count_;
  Hasher hasher_;
};

} // namespace jrl

#endif // JRL_UTIL_HASH_SET_GUARD
